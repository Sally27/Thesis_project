\chapter{Results}
\label{Sec:Results}

In this chapter the result of the \Lbpi branching fraction measurement will be presented in \autoref{sec:rel}. This will be followed by an overview of the systematic uncertainties on the \Lbpi branching fraction measurement in \autoref{Sec:Systematics}. %This is followed by the resulting branching fraction measurement, outlined in \autoref{sec:rel}.

\section[The $\Lbpi$ branching fraction measurement]{The $\mathbold{\Lbpi}$ branching fraction measurement}
\label{sec:rel}

The mass fit to \Lbpi data is shown in \autoref{Fig:freedom}.
\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \hspace*{-1.0cm}
  %% \subfloat[]{\includegraphics[scale = 0.6]{figs/pullfitted_nc_eXgtoy.pdf}\label{drefPULL:1}} \\
  %\subfloat[]{
  \includegraphics[height = 6cm]{figs/protonismSIG.png}%ppimumunblinded.png}
  %\label{drefPULL:2}}\hskip 0.04\textwidth
  \caption{The fit to the \Lbpi mass distribution.}% is shown for \protect\subref{drefPULL:1}, a free fit and  a fit with the RooExpAndGauss parameters constrained, \protect\subref{drefPULL:2}.}
  \label{Fig:freedom}
\end{figure}

The \Lbpi signal peak is observed with a $\SIG\sigma$ significance, where the significance  is calculated using Wilk's theorem, as previously discussed in \autoref{subsec:backfit}.

The \Lbpi event yield taken from the fit to the \Lbpi mass distribution is $\Syield$ events. Given that $\Nyield$ events are observed in the \Lbpijpsi fit and $\epsilon_{\Lbpi/\Lbpijpsi} = \tw$, the value of \BF(\Lbpi) is given as

\begin{equation}
  \begin{split}
    \BF(\Lbpi) & = 22 \times (1/0.487) \times (1/1017) \times \BF(\Lbpijpsi)\times\BF(\jpsi\to\mumu) \\
    & = \BFV\\
  \end{split}\end{equation}
where the first error is the statistical uncertainty, the second is the systematic uncertainty and the third is the uncertainty from \BF(\Lbpijpsi). The systematic uncertainties are discussed in detail in \autoref{Sec:Systematics}.

There are no theoretical predictions for the \Lbpi branching fraction. However, the yield of $\Syield$ is consistent with the estimated yield of 9 events at the $\DSIG\sigma$ level. The order of magnitude of the \Lbpi branching fraction is two orders of magnitude less than the \Lb\to\proton\pim\jpsi(\to\mumu) branching fraction and the ratio between \BF(\Lbpi) and \BF(\Lbpijpsi) is consistent with that of \BF(\LbL) and \BF(\Lb\to\Lz\jpsi).

A series of separate post-unblinding checks were performed to check for contamination from pions misidentified as muons. The PID requirements on both muons were tightened from $\dllmupi~>~-3$ to $\dllmupi~>~0$ and events with $2256<m_{p\pi\mu\to\pi}<2316\mevcc$ are vetoed in order to remove \Lc contributions. The \Lbpi mass distribution was then refitted, as shown in \autoref{Fig:postub}. After these additional \dllmupi selections the signal yield reduces by less than an event and the additional \Lc veto also reduces the signal by $\sim$ an event.  The significance after both these selections reduces to 5.3$\sigma$ and the branching fraction remains consistent with that calculated without these additional selections applied.

%% Second, a veto of $m_{p\pi\mu\to\pi}>2650\mevcc$ was placed on all events, in order to remove \Lc resonances, and the \Lbpi mass distribution was refitted, as shown in \autoref{Fig:postub}\protect\subref{PID:2}. For both cases the signal significance remains above 5$\sigma$.
\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \includegraphics[height = 6cm]{figs/protonismSIGpidmulcv.png}%masslc.png}\label{PID:1}} 
  %\subfloat[]{\includegraphics[height = 5cm]{figs/massmu.png}\label{PID:2}}\\%\hskip 0.04\textwidth
  \caption{The fit to the \Lbpi mass distributions for data candidates with $2256<m_{p\pi\mu\to\pi}<2316\mevcc$ events vetoed and with the requirement $\dllmupi>0$ placed on both muons.}
  \label{Fig:postub}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%55%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%55%%%%%%%%%



%% The mass fit to \Lbpi data is shown in \autoref{Fig:freedom}.
%% \begin{figure}[h!]
%%   \def\nh{0.7\textwidth}
%%   \centering
%%   \hspace*{-1.0cm}
%%   %% \subfloat[]{\includegraphics[scale = 0.6]{figs/pullfitted_nc_eXgtoy.pdf}\label{drefPULL:1}} \\
%%   %\subfloat[]{
%%   \includegraphics[height = 6cm]{figs/ppimumujpsiveto.png}%ppimumunblinded.png}
%%   %\label{drefPULL:2}}\hskip 0.04\textwidth
%%   \caption{The fit to the \Lbpi mass distribution.}% is shown for \protect\subref{drefPULL:1}, a free fit and  a fit with the RooExpAndGauss parameters constrained, \protect\subref{drefPULL:2}.}
%%   \label{Fig:freedom}
%% \end{figure}

%% The \Lbpi signal peak is observed with a $\SIG\sigma$ significance, where the significance  is calculated using Wilk's theorem, as previously discussed in \autoref{subsec:backfit}.

%% The \Lbpi event yield taken from the fit to the \Lbpi mass distribution is $\Syield$ events. Given that $\Nyield$ events are observed in the \Lbpijpsi fit and $\epsilon_{\Lbpi/\Lbpijpsi} = \tw$, the value of \BF(\Lbpi) is given as

%% \begin{equation}
%%   \begin{split}
%%     \BF(\Lbpi) & = 22 \times (1/0.487) \times (1/1017) \times \BF(\Lbpijpsi)\times\BF(\jpsi\to\mumu) \\
%%     & = \BFV\\
%%   \end{split}\end{equation}
%% where the first error is the statistical uncertainty, the second is the systematic uncertainty and the third is the uncertainty from \BF(\Lbpijpsi). The systematic uncertainties are discussed in detail in \autoref{Sec:Systematics}.

%% There are no theoretical predictions for the \Lbpi branching fraction. However, the yield of $\Syield$ is consistent with the estimated yield of 9 events at the 1.8$\sigma$ level. Similarly, a 5.2$\sigma$ or greater significance would be expected in $\sim$ 5\% of experiments, based on the expected significance of 2.8$\pm$1.2. The order of magnitude of the \Lbpi branching fraction is two orders of magnitude less than the \Lb\to\proton\pim\jpsi(\to\mumu) branching fraction and the ratio between \BF(\Lbpi) and \BF(\Lbpijpsi) is consistent with that of \BF(\LbL) and \BF(\Lb\to\Lz\jpsi)

%% A series of separate post-unblinding checks were performed to check for contamination from pions misidentified as muons. The PID requirements on both muons were tightened from $\dllmupi~>~-3$ to $\dllmupi~>~0$ and events with $2256<m_{p\pi\mu\to\pi}<2316\mevcc$ are vetoed in order to remove \Lc contributions. The \Lbpi mass distribution was then refitted, as shown in \autoref{Fig:postub}. After these additional selections the signal yield reduces by less than an event and the significance remains the same at 5.2$\sigma$ 

%% %% Second, a veto of $m_{p\pi\mu\to\pi}>2650\mevcc$ was placed on all events, in order to remove \Lc resonances, and the \Lbpi mass distribution was refitted, as shown in \autoref{Fig:postub}\protect\subref{PID:2}. For both cases the signal significance remains above 5$\sigma$.
%% \begin{figure}[h!]
%%   \def\nh{0.7\textwidth}
%%   \centering
%%   \includegraphics[height = 6cm]{figs/ppimumujpsivetopidlc.png}%masslc.png}\label{PID:1}} 
%%   %\subfloat[]{\includegraphics[height = 5cm]{figs/massmu.png}\label{PID:2}}\\%\hskip 0.04\textwidth
%%   \caption{The fit to the \Lbpi mass distributions for data candidates with $2256<m_{p\pi\mu\to\pi}<2316\mevcc$ events vetoed and with the requirement $\dllmupi>0$ placed on both muons.}
%%   \label{Fig:postub}
%% \end{figure}



\section[Systematic uncertainties on $\BF(\Lbpi)$]{Systematic uncertainties on $\mathbold{\BF(\Lbpi)}$}
\label{Sec:Systematics}
For the \Lbpi analysis, a range of sources of systematic uncertainty is studied.  All systematic uncertainties are quoted as a percentage of the value of the quantity whose uncertainty is being deduced, namely either the relative efficiency between the \Lbpi and \Lbpijpsi channels, or the uncertainty on the \Lbpi (\Lbpijpsi) yields extracted from the maximum-likelihood fits. In somes cases, the systematic uncertainty associated with a certain factor is deduced by comparing the nominal value of this factor against a value deduced by changing some aspects used in the calculation of this factor. In these cases, the error is quoted as either the difference between the nominal and changed value or as the error on the changed value, whichever is largest. The main systematic uncertainties considered for the \Lbpi analysis are:

\begin{description}
\item[Trigger] The TISTOS method, as discussed in \autoref{sec:tistos}, is applied to data and simulation to give an estimate of how accurate the simulation trigger efficiency estimation is.
\item[PID] The PID variables in the \LbKjpsi and \Lbpijpsi data channels are compared against the equivalent in simulation in order to quantify how well the PID distributions are modelled in simulation. %The bias induced by the removal of events from the resampled simulation is also investigated.
\item[The assumed $\mathbold{q^{2}}$ distribution] The $q^{2}$ distributions from \LbK sWeighted data is compared against that of $\LbL$ theoretical predictions in order to quantify the effect that changing the assumed $q^{2}$ distribution has on the total relative efficiency.
  \item[The assumed $\mathbold{m_{p\pi}}$ distribution] The $m_{p\pi}$ distribution from \Lbpijpsi sWeighted data is compared to that from phase space \Lbpi simulation in order to quantify the effect that changing the assumed $m_{p\pi}$ distribution has on the total relative efficiency. 
\item[The effect of the choice of fit model on the signal yield] To quantify the effect of the choice of fit model on the signal yield, constraints on the \Lbpi fit model were lifted and the fit redone. The model background was also altered and the fit repeated. %The effect of the fit model choice on the expected number of signal events observed is quantified.
  \item[Simulation reweighting and BDT efficiency] The effect that reweighting the simulation has on the final relative efficiency value is quantified by comparing the relative efficiency with and without the simulation weights applied. The total relative efficiency is also recalculated using the BDT efficiency taken from \LbK data. 
  \end{description}
\subsection{The TISTOS method}
The TISTOS method, as discussed in \autoref{sec:tistos}, refers to the use of data to calculate the trigger efficiency by assuming that TIS (Triggered Independent of Signal) and TOS (Triggered On Signal) events are independent. 
Thus the efficiency for the selection of TOS candidates can be expressed as
\begin{equation}
  \epsilon_{TOS}  = \frac{N_{TISTOS}}{N_{TIS}}.
\end{equation}
The trigger efficiency values for data and simulation  are compared by applying the TISTOS method to background-subtracted \LbKjpsi data and \LbKjpsi simulation. The \LbKjpsi channel is used due to the increased statistics in the \LbKjpsi data channel compared to the \Lbpijpsi and \Lbpi channels.  It is assumed that the difference between the \LbKjpsi data and simulation will be similar to the difference between \Lbpi data and simulation.  The trigger efficiency values in \autoref{Tab:tistos} are all given relative to the previous trigger level. % All trigger efficiency values are relative to the previous trigger level. %The simulation used has been weighted as in Section~\ref{Sec:Selection}. Tight PID cuts have been placed on data to reduce background.
%These results are shown in \autoref{Tab:tistos}.
The L0 and HLT1 trigger TISTOS efficiencies agree between data and simulation within 1$\sigma$ and the HLT2 trigger TISTOS efficiencies agree within 2$\sigma$.

%% \begin{table}[ht]
%%   \centering
%%   \begin{tabular}{l c c c c}
%%     \hline
%%     Trigger Level & simulation & data \\
%%     \hline
%%     L0 &   0.844$\pm$0.004 & 0.869$\pm$0.020\\
%%     HLT1 &  0.941$\pm$0.003 & 0.952$\pm$0.022\\
%%     HLT2 &   0.954$\pm$0.007 & 0.922$\pm$0.027\\
%%     \hline
%%      Total &   0.758$\pm$0.008 & 0.762$\pm$0.017\\
%% \hline
%%   \end{tabular}
%%   \caption{The trigger efficiency obtained using simulation and using the TISTOS method in data.}
%%     \label{Tab:tistos}
%% \end{table}

\begin{table}[ht]
  \centering
  \begin{tabular}{l c c c c}
    \hline
    Trigger Level & simulation & data \\
    \hline
    L0 &   0.867$\pm$0.002 & 0.869$\pm$0.020\\
    HLT1 &  0.942$\pm$0.001 & 0.952$\pm$0.022\\
    HLT2 &   0.965$\pm$0.003 & 0.922$\pm$0.027\\
    \hline
     Total &   0.788$\pm$0.004 & 0.762$\pm$0.017\\
     \hline
  \end{tabular}
  \caption{The trigger efficiency obtained using the TISTOS method in simulation and data.}
  \label{Tab:tistos}
\end{table}


The total difference in trigger efficiency between data and simulation is 3.4\% and this is assigned as a systematic uncertainty. % in the \jpsi case. Again, assuming that this is the same in the \mumu case, gives a combined error of 0.7\%, which is assigned as a systematic uncertainty on the relative efficiency measurement. %This is ignoring the statistical uncertainty on these differences.
\subsection{PID}
\label{sec:pidsys}
Resampled simulation is used to produce the distributions of the $p\dllppi$ and $\pi\dllkpi$ variables, as discussed in \autoref{sec:resample}. To quantify how well the PID is modelled in resampled simulation, the distributions of the PID variables, \dllppi and \dllkpi, are compared between data and resampled simulation using \LbKjpsi data which has better statistics than \Lbpijpsi. The data are shown in \autoref{Fig:resample}. %\protect\subref{resample:2}.% For the comparison between data and simulation for the $p\dllppi$ variable, \LbKjpsi data and simulation are used due to the better statistics in the data, as shown in \autoref{Fig:resample}\protect\subref{resample:2}. For the $\pi\dllkpi$ variable comparison, \Lbpijpsi data and simulation are used, as shown in \autoref{Fig:resample}\protect\subref{resample:3}.

The difference is then taken between data and resampled simulation for each bin in PID value, and the difference is fitted with a zero-order polynomial to extract the average difference between data and simulation. The difference between data and simulation is looked at between the range of 0 to 50 for the \dllppi variable, which disregards the cut-off at high \dllppi values discussed in \autoref{sec:resample}. The effect of this cut-off on the final efficiency is discussed below.  The difference between the data and simulation distributions for the \dllppi and \dllkpi PID variables are shown in \autoref{Fig:pid}. The values of the fitted constants in the zero-order polynomial fits shown in \autoref{Fig:pid}\protect\subref{pid:1} and \autoref{Fig:pid}\protect\subref{pid:2} are shown in \autoref{Tab:PID}. The results of both fits give a value for the fit constant that is consistent with zero\footnote{in the case of \autoref{Fig:pid}\protect\subref{pid:2} the distribution is not particularly flat, although the average is consistent with zero. However, even if there is some small deviation from a flat hypothesis for this PID variable, given that the same PID variables are used in the signal and normalisation channels, the effect on the relative efficiency of any mis-modelling of the PID distributions in the simulation will still be small} and no systematic uncertainty is assigned.    % and $\mu\mu$ channels in data and simulation for each individual PID variable.

\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  %% \hspace*{-1.5cm}
  %% \subfloat[]{\includegraphics[scale = 0.42]{figs/p_PIDp_resampled_edit}\label{resample:2}}
  %% \subfloat[]{\includegraphics[ scale = 0.35]{figs/KpiPIDredone}\label{resample:3}}\\

 % \hspace*{-1.3cm}
  %\vspace*{0.7cm}
  \subfloat[]{\includegraphics[width = 10cm]{figs/diffkpijpsimcdata.pdf}\label{pid:1}} \\
  \subfloat[]{\includegraphics[width = 10cm]{figs/diffppijpsimcdata.pdf}\label{pid:2}}\\%\hskip 0.04\textwidth
  \caption{The difference between data and simulation for the \dllkpi variable, \protect\subref{pid:1}, and the difference between data and simulation for the \dllppi variable, \protect\subref{pid:2}.}
  \label{Fig:pid}
\end{figure}

\begin{table}[ht]
   \centering
\begin{tabular}{l c c}
    \hline
    & \dllppi   & \dllkpi \\
    \hline
    Fit constant & $(3.0 \pm 18.0)\times 10^{-4}$& $(1.0 \pm 16.0)\times 10^{-4}$\\
    \hline
  \end{tabular}
  \caption{Value of the fit constant in the zero-order polynomial fit to the difference between data and resampled simulation as a function of PID variable.}
  \label{Tab:PID}
\end{table}



%% The statistical uncertainty from PIDCalib on the PID values is negligible compared to the statistical error on the simulation in each $p$, $\eta$ and $n_{t}$ bin, particularly for high $q^{2}$ bins, where there is very little data in phase space simulation. In addition, as the PID variables, and the selections made on them, are identical in both the signal and normalisation channels, the only difference between the efficiency of the PID selections on each channel will be due to difference in the decay kinematics. Any efficiency dependence on the kinematics can be studied by looking at the PID efficiency as a function of $q^{2}$. This dependency is shown in \autoref{Fig:trigpidint}. The PID efficiency is flat across the range $0<q^{2}<8$\gevcc, with a slight drop off for $q^{2}$ bins above the \jpsi veto.

%% %, due to softer hadrons. between the two channels  due to the different $q^{2}$ distributions

%% %% To quantify how accurately the relative efficiency for the PID selection is modelled in simulation, the relative efficiency between \LbK and \LbKjpsi in sWeighted data is compared with that extracted from simulation.

%% %The disadvantage with this cross-check method is the poor statistics in the \LbK data channel.

%% Examples of distributions comparing simulation and data from \LbK and \LbKjpsi, as well as \Lbpijpsi and \Lbpi simulation, can be seen in \autoref{Fig:pid}. These PID distributions for \Lbpi simulation assume a phase space distribution in $q^{2}$.
%% \begin{figure}[h!]
%%   \def\nh{0.7\textwidth}
%%   \centering
%%   \hspace*{-1.5cm}
%%   \subfloat[]{\includegraphics[scale = 0.45]{figs/pidKjpsimumucompMC.pdf}\label{pid:1}} 
%%   \subfloat[]{\includegraphics[scale = 0.45]{figs/piminuspidk_pk_jpsi_mumu_data_comp.pdf}\label{pid:2}}\hskip 0.04\textwidth
%%     \hspace*{-1.5cm}
%%   %% \subfloat[]{\includegraphics[scale = 0.45]{figs/ppluspidp_pk_jpsi_mumu_data_comp.pdf}\label{pid:3}} 
%%   \subfloat[]{\includegraphics[scale = 0.45]{figs/ppluspidp_pk_jpsi_mumu_MC_comp_edit}\label{pid:4}}
%%     \subfloat[]{\includegraphics[scale = 0.45]{figs/pidp_mumujpsipk.pdf}\label{pid:3}}\hskip 0.04\textwidth
%% %  /ppluspidp_pk_jpsi_mumu_data_comp.pdf
%%   \caption{The PID variables in different data and simulation samples as indicated in each legend.}
%%   \label{Fig:pid}
%% \end{figure}

%% As can be seen from \autoref{Fig:pid}\protect\subref{pid:1} and \autoref{Fig:pid}\protect\subref{pid:4}, the difference in the PID distributions between the \jpsi and \mumu channels is near-zero in simulation for both \Lbpi, \Lbpijpsi and \LbK, \LbKjpsi simulated events.

%% To compare the PID distributions of the \jpsi and \mumu channels in data, cuts are placed on \LbKjpsi and \LbK data at different places on the PID variables \dllppi and \dllkpi and the efficiency, relative to the cuts $\dllppi>0$ and $\dllkpi>5$, is calculated for each channel. The issue with this method is the limited precision on the efficiency values due to the low statistics in the \LbK channel. The results can be seen in \autoref{Tab:PID}.

%% \begin{table}[ht]
%%    \centering
%% \begin{tabular}{l c c c l}
%%     \hline
%%     Cut &        \LbKjpsi data   & \LbK data       & $\frac{\LbKjpsi}{\LbK}$ \\  
%%     \hline
%%     $\dllkpi>10$& 0.910$\pm$0.007& 0.844$\pm$0.061 & 1.078$\pm 0.075$\\          
%%     $\dllkpi>30$& 0.398$\pm$0.005& 0.362$\pm$0.040 & 1.100$\pm 0.122$\\          
%%     $\dllppi>10$& 0.992$\pm$0.008& 0.963$\pm$0.066 & 1.030$\pm 0.071$\\          
%%     $\dllppi>30$& 0.565$\pm$0.008& 0.463$\pm$0.077 & 1.220$\pm 0.204$\\          
%%     %% $\dllkpi>10$& 0.910$\pm$0.007& 0.844$\pm$0.061 &
%%     %% $\dllkpi>30$& 0.398$\pm$0.005& 0.844$\pm$0.040 &
%%     \hline
%%   \end{tabular}
%%   \caption{Efficiencies calculated using data from \LbK and \LbKjpsi for different PID cuts. In the column headers \LbKjpsi, \LbK indicate $\epsilon_{\LbKjpsi}$, $\epsilon_{\LbK}$.}
%%   \label{Tab:PID}
%% \end{table}

%% No significant difference is found between PID efficiency values for \LbK and \LbKjpsi data, although all values for \LbKjpsi data are higher than for \LbK. This could be due to the fact that higher $q^{2}$ events, which have lower PID efficiencies relative to the \jpsi $q^{2}$ bin, have more weight in data than in simulation, due to the simulation being phase space. Given that the values agree within error, no systematic is assigned. 

\subsubsection{The effect of the upper cut-off in the data calibration samples on the final relative efficiency}
\label{sec:cutpid}
As discussed in \autoref{sec:resample}, there is an upper cut-off at 50 on all the PID calibration samples from data used to resample the simulation. This translates to an effective cut-off in the PID distributions in resampled simulation.%, which uses these samples.

This does not affect the majority of the PID distributions used in this analysis, with the exception of the $p\dllppi$ distribution, where the cut at 50 removes 4.5\% of the \Lbpijpsi signal events. This value of 4.5\% is calculated using the \dllppi distribution given by sWeighted \Lbpijpsi data, as shown in \autoref{fig:jpsipidp}.

How much of an effect this cut-off at 50 in resampled simulation has on the total relative efficiency depends largely on two factors. Firstly, if the efficiency distribution for these events in the $\dllppi>50$ window is flat or varied with $q^{2}$, relative to the \jpsi bin in $q^{2}$, and secondly, whether or not the proportion of events in this $\dllppi>50$ window is similar for both the \Lbpi and \Lbpijpsi channels.

\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \includegraphics[width = 10cm]{figs/pplus_PIDpjpsi.pdf}
  \caption{The \dllppi distribution for sWeighted \Lbpijpsi after the application of all selections.}
  \label{fig:jpsipidp}
  \end{figure}

Given that protons with a higher momentum will be easier to identify in the RICH, high values of \dllppi are more likely to be associated with low values of $q^{2}$, where it is found that the PID efficiency is fairly flat. However, if the extreme case were assumed, i.e. that the efficiency across this region of $\dllppi>50$ in the \Lbpi channel differs from the efficiency in the \Lbpijpsi channel by the maximal amount observed in \autoref{Fig:trigpidint}, this would yield an efficiency difference of $\sim$ 20 \% between the two channels. Thus, if it is assumed that the proportion of events in the $\dllppi>50$ window is the same in the \Lbpi and \Lbpijpsi channels, the maximum effect on the total integrated relative efficiency that this cut-off at 50 could have would be 20\% of 4.5\%, giving 0.9\%.

To deduce whether or not the proportion of events in the $\dllppi>50$ window is similar between the \Lbpijpsi and \Lbpi channel, the \LbK and \LbKjpsi channels in data are used as a proxy. The proportion of events in this $\dllppi>50$ window is compared between the \LbK and \LbKjpsi channel and it is assumed that these proportions will be similar in the \Lbpijpsi (\Lbpi) case. For \LbKjpsi data,  94$\pm$2\% of events fall outside the $\dllppi>50$ window, and in the \LbK case it is 93$\pm$15\% of events. Taking the 15\% statistical error as the difference in proportions of $\dllppi>50$ events between the \LbK and \LbKjpsi channels, and combining this with the previous value of 0.9\%, gives a maximum difference in the total integrated efficiency of 1.0\%. This is, of course, an approximate estimate, but it indicates that it is reasonable to assume that the effect of this upper cut-off is small. This 1.0\% is assigned as a systematic uncertainty.


%% If the  the proportion of events in this $\dllppi>50$ window is not the same between the \Lbpi and \Lbpijpsi channels, but instead the 15\% error on the proportion calculation from \LbK, of 93$\pm$15\%, is taken as a proxy for the difference between the proportion of events in this $\dllppi>50$ window in the \Lbpi and \Lbpijpsi channels, a total error of 1.03\% on total integrated efficiency i. 


\subsection[The effect of the choice of the $q^{2}$ distribution on the total relative efficiency]{The effect of the choice of the $\mathbold{q^{2}}$ distribution on the total relative efficiency}
\label{subsec:bdtq2}
The total efficiency will depend on which $q^{2}$ distribution is used as a proxy for the signal $q^{2}$ distribution. The nominal proxy used is taken from the \LbL differential branching theory predictions, which were shown in \autoref{Fig:phsp}.

As an additional study, the $q^{2}$ distribution from \LbK data is used as an alternative to calculate the total integrated efficiency, although the statistics are limited. The \LbK kinematics should be similar to those from \Lbpi, although the range in $q^{2}$ for \LbK will be smaller, due to the heavier kaon. The total integrated efficiency calculated using the $q^{2}$ distribution from \LbK data and \LbL branching fraction predictions are compared. The \LbK data is sWeighted and, in order to deduce the proportion of \LbK events that fall into the $q^{2}$ vetoes, the $q^{2}$ distribution is fitted with a generic polynomial, as shown in \autoref{Fig:q2pkfit}. The fit is applied across the whole range in $q^{2}$, including the vetoed regions. %, and as already mentioned, the range of the dimuon spectrum in \LbK data will be less then that in \Lbpi data, due to the mass difference between the kaon and pion.  

\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \includegraphics[width = 10cm]{figs/pol7_q2.pdf}
  
%  \caption{The $q^{2}$ distribution taken from sWeighted \LbK data fitted with a polynomial.}
    \caption{The $q^{2}$ distribution for sWeighted \LbK data fitted with a polynomial function.}
  \label{Fig:q2pkfit}
\end{figure}

It is estimated from the fit in \autoref{Fig:q2pkfit} that 67.8\% of \LbK events remain following the $q^{2}$ vetoes, giving a total efficiency integrated over $q^{2}$ of $\twq2$. The error quoted here considers only the statistical error on the \LbK data and not the statistical error on the simulation, which is considered as a separate source of systematic uncertainty in \autoref{sec:rew}.  This efficiency value is consistent with the nominal value of $\tw$ computed in \autoref{Sec:Eff}. However the statistical error on the relative efficiency calculated using the $q^{2}$ distribution from \LbK data is taken as an estimate of the systematic uncertainty on the relative efficiency associated with the modelling of the $q^{2}$ distribution. This gives an uncertainty of 7.9\%. %of (3.4/50.5)\% = 6.7\%.

%% differing by 2.3\% from this nominal value.  However, there is a large statistical uncertainty on the integrated efficiency taken using the \LbK $q^{2}$ proxy, of (50.2 $\pm$ 6.0)\%, giving a fractional uncertainty of 6.0/50.2 = 12.0 \%. This statistical uncertainty includes the statistical uncertainty on the efficiency values in each $q^{2}$ bin which arise from the statistics in the simulation however, which is already taken into account in a different systematic, discussed in \autoref{sec:rew}. Thus, to avoid double-counting, the statistical percentage error obtained on the efficiency value is recalculated, only taking into account the error on each $q^{2}$ bin due to the error on the \LbK $q^{2}$ distribution. This gives a total intergrated relative efficiency of (50.2 $\pm$ 4.2)\%, giving a percentage error of 8.3\%, which is added as a systematic uncertainty. % .
\subsubsection[Effect of limiting the range in $q^{2}$ on the total integrated efficiency]{Effect of limiting the range in $\mathbold{q^{2}}$ on the total integrated efficiency}
\label{sec:limit}
As discussed in \autoref{sec:toteff}, the final $q^{2}$ bin of (19$<q^{2}<20) \gev^{2}/c^{4}$ has extremely limited statistics in phase space simulation after selection, meaning it cannot be included in the total efficiency integration over $q^{2}$. However, all bins above $15 \gev^{2}/c^{4}$ have a relative efficiency of less than unity. Assuming therefore that the maximum relative efficiency this $q^{2}$ bin could have is unity, and the minimum value of efficiency this bin could have is zero, the maximum possible change to the relative efficiency is 2.5\%.  This value is derived from \LbL theory predictions which have 2.5\% of events in the (19$<q^{2}<20) \gev^{2}/c^{4}$ $q^{2}$ bin. This 2.5\% is taken as a systematic uncertainty on the relative efficiency value.



%% If this final bin is included, the yielded efficiency is (51.1$\pm$6.9)\%, which is consistent with the nonmial value of (49.1\pm3.1)\%. The difference between them of 4.1\% is taken as a systematic. 

\subsection{The effect of the choice of the BDT efficiency proxy on the total relative efficiency}
The nominal BDT efficiency was computed from \LbKjpsi events and assumed to be flat in $q^{2}$. To quantify the effect that this assumption has on the relative efficiency, the BDT efficiency is recalculated using \LbK data.  The distribution $\epsilon_{i}\times N_{q^{2}_{i}}/N$, defined in \autoref{sec:toteff}, for the BDT efficiency taken from either \LbKjpsi or \LbK data, combined with the $q^{2}$ shape taken from \LbL branching fraction predictions, is shown in \autoref{Fig:q2timeseff}. For events above $15\gev^{2}/c^{4}$ in \LbK data, the nominal value from \LbKjpsi data is used, as there are less than five events in \LbK data in this bin, making an efficiency calculation using \LbK data impractical.

The total integrated efficiency assuming a BDT efficiency taken from \LbK data is $\twbdt$, which is consistent with the $\tw$ taken using \LbKjpsi data as a proxy for the BDT efficiency. The difference between these two values is quoted as a fraction of the nominal efficiency of $\tw$, giving a systematic uncertainty of 5.6\%.

%% The dominant uncertainty here comes from the statistical uncertainty on the efficiency value calculate using \LbK data as a BDT proxy. The statistical error on this efficiency value has an uncertainty of 3.2\%, which is quoted as a systematic.

%and the total integrated relative efficiency for each case is shown in \autoref{tab:toteff}.


%% The systematic uncertainty due to the assumption of a flat BDT efficiency is combined with the systematic uncertainty due to the simulation reweighting, discussed in \autoref{sec:rew}.



%% The $q^{2}$ distribution from \BdToKstmm physics simulation is tried as an alternative to the \LbL theoretical branching fraction predictions nominally used. The \BdToKstmm physics simulation is used as it not just generated in phase-space, but invokes a well understood physics model.  Both of these distributions can be seen in \autoref{Fig:kstlbq2}, along with the regions in $q^{2}$ which are vetoed.


%% In addition, the choice of the BDT efficiency distribution as a function of $q^{2}$, whether taken from \LbKjpsi or \LbK data, will also effect the final total relative efficiency. The distribution $\epsilon_{i}\times N_{q^{2}_{i}}/N$ for these four possibilities (i.e. the BDT efficiency taken from either \LbKjpsi or \LbK data combined with the $q^{2}$ shape taken from either \LbL theory or \BdToKstmm simulation) is shown in \autoref{Fig:q2timeseff} and the total integrated relative efficiency for each case is shown in \autoref{tab:toteff}.

\begin{figure}[h]
  \centering
  \includegraphics[width = 10cm, trim = 0mm 0mm 0mm 0mm, clip=true]{figs/bdtprodnoprodjpsi.pdf}
  \caption{The total efficiency as a function of $q^{2}$ multiplied by the \LbL $q^{2}$ distribution and assuming either a flat or varying BDT efficiency distribution in $q^{2}$.}
  \label{Fig:q2timeseff}
\end{figure}

\subsection{Effect of weighting the simulation and the simulation statistics on the total integrated efficiency value}
\label{sec:rew}
The final relative efficiency is $\tw$ which gives a 4.4\% uncertainty on the relative efficiency value. This error comes from the combination of the uncertainty on the efficiency values on each $q^{2}$ bin, due to the simulation statistics, and also the error on the $q^{2}$ distribution itself, taken from the theoretical error on the \LbL branching fraction predictions. %The dominating source of statistical error of the simulation is from the high $q^{2}$ in the \Lbpi simulation.

The effect that reweighting the simulation has on the total integrated efficiency value is studied by comparing the total integrated relative efficiency computed where the simulation has been weighted and not weighted, as outlined in \autoref{sec:reweight}. The comparison of these two relative efficiencies as a function of $q^{2}$ is shown in \autoref{Fig:toteffB}. The integrated efficiency for the weighted case is $\tw$ and for the unweighted case it is $\tnw$. This gives a difference of 1.1\% between the two values, which is assigned as a systematic uncertainty.

In addition, the efficiency calculated by weighting simulation using \LbKjpsi data, instead of \Lbpijpsi data, is calculated and compared with the nominal relative efficiency value. This is found to be $\twPK$ which gives a difference of 0.6\% with the nominal value which is also assigned as a systematic uncertainty. This gives a total systematic uncertainty, due to the reweighting on the simulation, of 1.3\%.


\begin{figure}[h]
  \centering
%  \hspace*{1cm}
  \includegraphics[width = 10cm]{figs/wnw_jpsiveto.pdf}%wnwjpsiw.pdf}
    \caption{ The total relative efficiency calculated with weighted simulation, compared against the efficiency calculated using non-weighted simulation.}
\label{Fig:toteffB}

\end{figure}


%% the same process as detailed at the start of \autoref{subsec:bdtq2} is repeated but for the case where the simulation has not been weighted. This gives the total integrated relative efficiency values as shown in \autoref{tab:toteffNW} and a comparison of the relative efficiency as a function of $q^{2}$, calculated using either weighted or non-weighted simulation, can be seen in \autoref{Fig:toteffB}.
%% \begin{table}[tb]
%%   \centering
%%   \hspace*{-1cm}
%%   \begin{tabular}{l|c|c} %
%%     \hline
%%     $q^{2}$ distribution &BDT eff. from \LbKjpsi data& BDT eff. from \LbK data\\
%%     \hline
%%     \LbL theory. & 0.510$\pm$0.013 & 0.506$\pm$0.016\\
%%     \BdToKstmm sim. & 0.503$\pm$0.005& 0.494 $\pm$0.010\\
%%     \hline % grepme3
%%   \end{tabular}
%%   \caption{The total relative efficiency between \Lbpi and \Lbpijpsi channels for differing scenarios for the choice of $\sum_{i}$ $\epsilon_{i}\times$ $N_{q^{2}_{i}}/N$, calculated using non-weighted simulation.}
%%     \label{tab:toteffNW}
%% \end{table}


%% \begin{figure}[!t]\def\nh{0.3\textwidth}
%%   \centering
%%   \includegraphics[scale = 0.6]{figs/w_now.pdf}
%%     \caption{ The total relative efficiency (minus that of the BDT) calculated with weighted simulation, compared against the efficiency calculated using non-weighted simulation.}
%% \label{Fig:toteffB}

%% \end{figure}

%% The largest difference between the nominal total relative efficiency value used, and any other entry in \autoref{tab:toteff} and \autoref{tab:toteffNW}, is found in the case when the integrated relative efficiency value is calculated using non-weighted simulation, the BDT efficiency is calculated using \LbK data and \BdToKstmm theory predictions are used as a proxy for the $q^{2}$ signal distribution. The difference between this scenario (where the efficiency = 0.494$\pm$0.010) and the nominal case (where the integrated efficiency value is calculated using weighted simulation, the BDT efficiency is calculated using \LbKjpsi data and \LbL theory predictions are used as a proxy for the $q^{2}$ signal distribution) gives a difference of 3.3\% on the efficiency value, which is addeds a systematic uncertainty to the relative efficiency value. 

\subsection[Effect of reweighting the $p\pi$ mass  spectrum in simulation on the total integrated efficiency]{Effect of reweighting the $\mathbold{p\pi}$ mass  spectrum in simulation on the total integrated efficiency}
\label{sec:ppisys}
The $p\pi$ mass spectrum, $m_{p\pi}$, in phase space simulation is known to be incorrectly modelled for both \Lbpi and \Lbpijpsi. This is shown in \autoref{Fig:allppi}, which shows sWeighted \Lbpijpsi data and phase space (phsp) simulation for both the \Lbpi and \Lbpijpsi channels.

\begin{figure}[h!]
  %\def\nh{0.7\textwidth}
  \centering
  \includegraphics[width = 10cm]{all_ppi_plots}
    \caption{The $p\pi$ mass spectrum for sWeighted \Lbpijpsi data and phase space (phsp) \Lbpi and \Lbpijpsi simulation.}
  \label{Fig:allppi}

  \end{figure}


To quantify the effect of this incorrect modelling, \Lbpijpsi sWeighted data is used to reweight the $p\pi$ mass spectrum in \Lbpi and \Lbpijpsi simulation. As the range in the dihadron mass spectrum for \Lbpijpsi data is smaller than for \Lbpi data, due to the narrower dimuon spectrum in the \Lbpijpsi case, the reweighting is done with a cut placed at $m_{p\pi}<2500\mevcc$  on both \Lbpijpsi data and \Lbpi and \Lbpijpsi  simulation. The comparison between \Lbpijpsi data and \Lbpi simulation after reweighting in $m_{p\pi}$ is shown in \autoref{Fig:mppi} and the relative efficiency as a function of $q^{2}$ for the $m_{p\pi}$ weighted and unweighted case is shown in \autoref{Fig:mppiq2}.

The $m_{p\pi}$ weighted \Lbpijpsi and \Lbpi simulation is used to calculate the efficiency, relative to the \jpsi $q^{2}$ bin. The comparison between the relative efficiency with and without the dihadron weights applied is taken as a percentage of the unweighted value, giving a difference of 7.7\%. This is assigned as the systematic uncertainty arising from the mismodelling of the $m_{p\pi}$ spectrum in simulation. %  which is assigned as a systematic. 

\begin{figure}[h!]
  %\def\nh{0.7\textwidth}
  \centering
  \includegraphics[width = 10cm]{jpsiontopofmumu.pdf}
    \caption{The $p\pi$ mass spectrum for \Lbpijpsi data and $m_{p\pi}$ weighted \Lbpi simulation, with a cut placed at $m_{p\pi}<2500$\mevcc.}
  \label{Fig:mppi}

  \end{figure}

\begin{figure}[h!]
  %\def\nh{0.7\textwidth}
  \centering
  \includegraphics[width = 10cm]{weightunweightrel.pdf}
    \caption{The efficiency as function of $q^{2}$ for \Lbpi simulation with $m_{p\pi}$ weights applied and not applied, with a cut placed at $m_{p\pi}<2500$\mevcc.}
  \label{Fig:mppiq2}

  \end{figure}
\FloatBarrier
\subsection{Effect of the fit shape on the fitted signal yield}
\label{sec:sysfit}
The effect of the chosen fit shape model on the fitted signal yield is evaluated via various approaches. The first approach outlined in this section involves the comparison between the number of signal events given by the fit when the fit is constrained using Gaussian constraints on the RooExpAndGauss part-reco component and when these constraints are lifted. The second approach considers the effect of adding the \LbK mass component to the \Lbpi signal fit. The third approach involves a complete change of background  model from a RooExpAndGauss and exponential to a single exponential and a change in the fit range.
%This is discussed in \autoref{sec:rr}. , discussed in \autoref{sec:syspk}, discussed in \autoref{sec:rang}.
\subsubsection{Lifting the constraints on the signal fit}
\label{sec:rr}
To compare the number of signal events given by the fit when the fit is constrained using Gaussian constraints on the RooExpAndGauss part-reco component and when these constraints are lifted, the number of signal events for either case are taken from fits to 1000 pseudo experiments. The pseudo experiments are generated using the same procedure as outlined in \autoref{subsec:sig}, using the expected signal yield, $n_{sig}$, of $n_{sig} = 9$. Some examples of pseudo experiments fitted with no constraints are shown in \autoref{Fig:pseudo-experimentssys}.
\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \vspace*{-1.5cm}
    \hspace*{-1.5cm}%\vspace*{-1cm}
    \subfloat[]{\includegraphics[scale = 0.5]{figs/200_nofixtoy_edit_edit.png}\label{dreftoy:1}} \\
    \hspace*{-1.5cm}
  \subfloat[]{\includegraphics[scale = 0.5]{figs/free_exp_g_800_edit_edit.png}\label{dreftoy:2}}
  \caption{Examples of pseudo experiments showing background and signal fits, (left) and background only fits, fitted back with a RooExpAndGauss and exponential combined model with none of the fit components constrained, (right). The significance is 1.04 for the fits in \protect\subref{dreftoy:1} and 4.32 for the fits in  \protect\subref{dreftoy:2}. The no. S and no. B in the legends refer to the number of signal and background events respectively.}
  \label{Fig:pseudo-experimentssys}
\end{figure}

%% The fit to the distribution of the number of signal events from the pseudo experiments, fitted with either a constrained or free fit, can be seen in \autoref{Fig:nsig}.

%There are slightly fewer pseudo experiments in the free case, as some of the free fits did not converge properly and these were removed.
The average number of signal events for the case where the fit is not constrained is $8.37\pm0.17$, and for the case where the fit is constrained it is $8.98\pm0.14$. The difference in the average number of signal events between a free and constrained fit is therefore 0.62, which, when quoted as a fraction of the average number of signal events from the nominal constrained fit, corresponds to an error of 6.9\%. This is taken as a systematic uncertainty on the \Lbpi signal yield. %1.8\%

%% \begin{figure}[h!]
%%   \def\nh{0.7\textwidth}
%%   \centering
%%      % \hspace*{-2.5cm}
%%   \subfloat[]{\includegraphics[scale = 0.6]{figs/no_sig_free.pdf}\label{drefN:1}} \\
%%   \subfloat[]{\includegraphics[scale = 0.6]{figs/no_sig_constr.pdf}\label{drefN:2}}\hskip 0.04\textwidth
%%   \caption{The fit to the distribution of the number of signal events taken from each pseudo experiment fit is shown for a free fit, \protect\subref{drefN:1}, and a fit with the RooExpAndGauss parameters constrained, \protect\subref{drefN:2}. The bins containing zero signal events are included in the fit in \protect\subref{drefN:1}.}
%% \label{Fig:nsig}
%% \end{figure}
\FloatBarrier
\subsubsection{Addition of a $\boldsymbol{\LbK}$ component to the fit}
\label{sec:syspk}
The expected number of \LbK events in the \Lbpi channel after selection is 1$\pm$1 event and only $\sim$20\% of \LbK events are expected to fall in the signal region. Given that only 0.2 events are expected, no fit component is added. The effect on the \Lbpijpsi yield of adding or removing the \LbKjpsi component to the \Lbpijpsi fit is 1.6\%. This 1.6\% is added as a systematic uncertainty on the \Lbpi signal yield. 

\subsubsection{Changing the background model}
\label{sec:rang}
A fit to background-only data, where the blinded region is not included in the fit, is repeated twice. The fit is performed once with the nominal RooExpAndGauss plus exponential model, across the full fit range of $5100-7000\mevcc$, as indicated by the blue curve in \autoref{F}, and once with an exponential-only model with a restricted range of $5500-7000\mevcc$, indicated with the red curve in \autoref{F}. This restricted range is designed to avoid the inclusion of the the part-reco shoulder at low mass. %but over a range which does not include the part-reco shoulder, using an exponential-only model. The comparison between the two cases is shown in \autoref{F}.

\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
     % \hspace*{-2.5cm}
  \includegraphics[scale = 0.6]{figs/fitsystfinal.pdf}
  \caption{The background-only fit for the nominal background model over the full range of $5100-7000\mevcc$ and a background-only fit with a single exponential over the restricted range of $5500-7000\mevcc$.}
  \label{F}
\end{figure}
%% In the case of the nominal model, the nominal range is also used. In the case of the exponential. the range is taken from 5500-5700\mevcc. The blinded region is not included in the fits, as indicated by the downwards step in \autoref{F}.

The number of fitted events, combined with the relevant fit parameters, is used to calculate the number of events in the blinded region. In the case of the nominal model, 1.89 events are expected in the signal region. For the exponential-only model it is 1.93 events. This correspond to a change of 2.1\% on the nominal expected background level and a change of 0.4\% on the number of signal events, assuming $n_{sig} = 9$. Given the negligible size of this error, no systematic uncertainty is assigned. 



\subsection{Verifying the fit coverage and bias for the signal channel}
\label{sec:pull}
To verify the fit coverage and bias, the pull is calculated for the nominal fit model fitted using pseudo data, which are again generated with $n_{sig}$ = 9. The pull is defined by the difference in the number of signal events given by the pseudo experiment fits and the original number of signal events the pseudo experiments were generated with, divided by the error on the number of signal events given by the fit. Due to the low statistics in the signal channel, the assumption that the error on the signal yield given by the fit is symmetric is not valid. Instead, the asymmetric error is used to calculate the pull, where the uncertainty taken from above the signal yield is used for pseudo experiments with a signal yield lower than the generated number, and vice versa for pseudo experiments with a signal yield lower than the generated number. The pull is calculated for 10000 pseudo data sets, and the fit to the distribution of the pulls is shown in \autoref{Fig:pull}.
\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
%  \hspace*{-2.5cm}
  %% \subfloat[]{\includegraphics[scale = 0.6]{figs/pullfitted_nc_eXgtoy.pdf}\label{drefPULL:1}} \\
  %\subfloat[]{
  \includegraphics[width = 10cm]{figs/pullshilomumu.pdf}%constr_pull}
  %\label{drefPULL:2}}\hskip 0.04\textwidth
  \caption{The fit to the distribution of the pseudo experiment's pulls for the signal channel fit. }% is shown for \protect\subref{drefPULL:1}, a free fit and  a fit with the RooExpAndGauss parameters constrained, \protect\subref{drefPULL:2}.}
  \label{Fig:pull}
\end{figure}


The value of the mean of the pull distribution is 0.080$\pm$0.011 and the value of the standard deviation is 0.986$\pm$0.008. The standard deviation therefore is consistent with unity at the level of 1.8$\sigma$. The mean however has a significant deviation from zero, meaning the fit has a slight bias towards lower signal yields. This bias corresponds to 8\% of the error on the signal yield from the signal fit and this is taken as a systematic uncertainty. To gauge the size of this error, assuming that the error from the signal fit will be roughly of order $\sim$ 30\%, 8\% of 30\% corresponds to an error of size 2.5\%.  This fit bias is not corrected for, instead it is taken into account with an additional systematic uncertainty.
\subsection{Verifying the fit coverage and bias for the normalisation channel}
To verify the fit coverage and bias for the normalisation channel, the same procedure as carried out in \autoref{sec:pull} is repeated for the case of the fit to $\Lbpijpsi$ data, again using 10000 pseudo experiments but taking $n_{sig}$ = $\Nyield$ for the number of signal events. The fit to the distribution of the pulls is shown in  \autoref{Fig:pulljpsi}. The mean from the fit to the pull distribution is consistent with zero at the 0.6$\sigma$ level and the standard deviation from the fit is consistent with unity at the 0.3 $\sigma$ level.
\begin{figure}[h!]
  \def\nh{0.7\textwidth}
  \centering
  \hspace*{-1.0cm}
  %% \subfloat[]{\includegraphics[scale = 0.6]{figs/pullfitted_nc_eXgtoy.pdf}\label{drefPULL:1}} \\
  %\subfloat[]{
  \includegraphics[width = 10cm]{figs/jpsipulls10000}
  %\label{drefPULL:2}}\hskip 0.04\textwidth
\caption{The fit to the distribution of the pseudo experiment's pulls for the normalisation channel fit. }% is shown for \protect\subref{drefPULL:1}, a free fit and  a fit with the RooExpAndGauss parameters constrained, \protect\subref{drefPULL:2}.}
  \label{Fig:pulljpsi}
\end{figure}



%% \subsubsection{Bias to mass shapes because of mass-dependent PID cuts}
%% To verify that the mass dependent PID cuts do not affect the shape of the combinatorial background to the extent where it can no longer be modelled using a single exponential function, the region above 6000\mevcc, which is assumed to be comprised of only combinatorial background, is studied. The mass dependent PID cuts, outlined in \autoref{tab:refl}, are shifted 1\gevcc higher, such that they affect the region above 6000\mevcc. The data in this region is shown in \autoref{Fig:wworefl}\protect\subref{drefsh:1} with all initial selection and PID cuts applied, with and without the additional mass-dependent PID cuts. The shape of the mass distribution after the mass dependent PID cuts have been applied is still consistent with an exponential. %The distribution of events after the mass-dependent PID cuts have been applied 
%% The effect of these mass-dependent PID cuts on the signal shape is investigated by applying the mass cuts to resampled simulation. These efficiencies used to weight the simulation are the absolute efficiencies, not the relative efficiencies. The mass-dependent PID cuts do not bias the signal shape, as shown in \autoref{Fig:wworefl}\protect\subref{drefsh:2}, which shows the resulting signal shapes, both normalised,  with and without the mass-dependent PID vetoes applied. Even if there were a significant effect on the shape, the effect on the ratio of \Lbpi and \Lbpijpsi efficiencies would be negligible.% is reasonable to assume that theses effects would be similar in both \Lbpi and \Lbpijpsi channels. 
%% \begin{figure}[h!]
%%   \def\nh{0.7\textwidth}
%%   \centering
%%   \hspace*{-0.7cm}
%%   \subfloat[]{\includegraphics[width = 10cm]{figs/1gev_refl_test.pdf}\label{drefsh:1}} 
%%   \subfloat[]{\includegraphics[width = 10cm]{figs/signalw_wo_PIDcuts}\label{drefsh:2}}\hskip 0.04\textwidth
  
%%   \caption{The shape of \Lbpi data above 6000\mevcc, with mass-dependent PID cuts applied 1\:\gevcc higher and not applied at all, \protect\subref{drefsh:1} and the normalised shape of the signal shape, taken from simulation, with and without the mass-dependent PID cuts applied, \protect\subref{drefsh:2}.}
%%   \label{Fig:wworefl}
%% \end{figure}
%% \FloatBarrier

%% \clearpage

\subsection[Errors on the $\Lb\to\proton\pim\jpsi(\to\mumu)$ branching fraction measurement]{Errors on the $\mathbold{\Lb\to\proton\pim\jpsi(\to\mumu)}$ branching fraction measurement}
The branching fraction for \Lbpijpsi is measured relative to that of the \LbKjpsi decay, by combining the measurements in Ref.~\cite{LbKjpsi} and Ref.~\cite{LHCb-PAPER-2014-020}. The \Lbpijpsi branching fraction is given as

\begin{equation}
  (2.61 \pm 0.09 \pm 0.13^{+0.47}_{-0.37})\times 10^{-5},
\end{equation}
where the first uncertainty is statistical, the second is due to the systematic uncertainty on \BF(\Lbpijpsi)/\BF(\LbKjpsi), and the third is due to the systematic uncertainty on \BF(\LbKjpsi). %The error on the branching fraction \BF(\jpsi\to\mumu) is considered to be negligibly small.

In turn, the \LbKjpsi branching fraction is measured relevant to \BdToJPsiKst in Ref.~\cite{LbKjpsi} and is given as

\begin{equation}
  (3.17 \pm 0.04\pm0.07\pm0.34^{+0.45}_{-0.28})\times 10^{-4},
\end{equation}
where the first uncertainty is statistical, the second is due to the systematic uncertainty, the third is due to the uncertainty on the branching fraction of \BdToJPsiKst, and the fourth is due to the knowledge of the fraction of \Lb baryons produced within LHCb by the number of \Bd mesons produced, $f_{\Lb}/f_{d}$. The error on \BF(\LbKjpsi) is dominated by the uncertainty on $f_{\Lb}/f_{d}$ and on \BF(\BdToJPsiKst), which in turn dominates the error on the \Lbpijpsi branching fraction.

The total error on \BF(\Lbpijpsi) is $^{+19\%}_{-15\%}$, making it the dominant systematic on the \Lbpi branching fraction. %When measuring the absolute branching fraction of \Lbpi, this error from \BF(\Lbpijpsi) will have to be taken into account. However, when combining \BF(\Lbpi) with \BF(\LbK) to extract $|\Vtd/\Vts|$, this error can be disregarded as \BF(\Lbpi) is measured relevant to \BF(\Lbpijpsi) and \BF(\LbK) will be measured relevant to \BF(\LbKjpsi), meaning \BF(\Lbpi)/\BF(\LbK) will be proportional to \BF(\Lbpijpsi)/\BF(\LbKjpsi), which has already been measured in Ref~\cite{LHCb-PAPER-2014-020}.

  \subsection{Summary of systematic uncertainties}
  A summary of the systematic uncertainties  can be found below in \autoref{Tab:sys}

\begin{table}[ht]

  \centering

  \begin{tabular}{l c c c c}
    \hline
    Error source & Error Assigned/\% \\
    \hline
    Error on \BF(\Lbpijpsi) & $^{+19}_{-15}$\\
    Error on \BF(\jpsi\to\mumu) & 0.5\\
    \hline
    Error on efficiency ratio\\
    \hline
    $q^{2}$ distribution &  7.9  \\
    $p\pi$ weighting&  7.7  \\
    
    Choice of BDT efficiency proxy&  5.6  \\
    Error due to simulation statistics &  4.4  \\
    
    Trigger &  3.4    \\    
    Error due to the removal of last $q^{2}$ bin  & 2.5\\
    Kinematic weighting&  1.3  \\
    PID  &  1.0  \\
    \hline
    Error on normalisation and signal yields\\
    \hline
    Effect of the fit shape &  6.9  \\
    Error on number of \Lbpijpsi events & 4.0\\
    Fit bias & 2.2 \\
    Effect of the \LbK component&  1.6  \\
    
    \hline

    Without \BF(\Lbpijpsi) error & 16.1 \\\hline
        Total & $^{+25}_{-22}$ \\\hline
    
     %Total & 8.9 \\

  \end{tabular}

  \caption{The different sources of systematic uncertainty and the total systematic uncertainty assigned.}
    \label{Tab:sys}
\end{table}

Although the resultant 16\% systematic error, when disregarding the systematic uncertainty on \BF(\Lbpijpsi), is large, the statistical error is of order 30\% and thus the statistical error is still dominant. The dominant systematic is from the uncertainty of the phase space simulation's ability to successfully model the kinematics of the decay, as reflected in the 7.9\% and 7.7\% uncertainties on the effect of the dimuon and dihadron mass spectrum modelling on the efficiency respectively.



%The fit was redone with the requirement $\dllmu>2$ placed on both muons and 

%Tightebing muon PID 0 = 5.82 sigma (22.7)PID 2 5.24 sigma (17.5).

%Put in veto plot as well
\clearpage
 
